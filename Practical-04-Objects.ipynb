{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:left\">\n",
    "    <h1 style=\"width:450px\">Practical 4: Object-Oriented Programming</h1>\n",
    "    <h2 style=\"width:450px\">Getting to grips with Functions &amp; Packages</h2>\n",
    "</div>\n",
    "<div style=\"float:right\"><img width=\"100\" src=\"https://github.com/jreades/i2p/raw/master/img/casa_logo.jpg\" /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: dotted 1px rgb(156,121,26); padding: 10px; margin: 5px; background-color: rgb(255,236,184); color: rgb(156,121,26)\"><i>Note</i>: You should download this notebook from GitHub and then save it to your own copy of the repository. I'd suggest adding it (<tt>git add ...</tt>) right away and then committing (<tt>git commit -m \"Some message\"</tt>). Do this again at the end of the class and you'll have a record of everything you did, then you can <tt>git push</tt> it to GitHub.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisiting Task 4. Why 'Obvious' is Not Always 'Right'\n",
    "\n",
    "Task 4 in Practical 3 is hard, especially coming at the end of an already challenging practical. So I want to provide _another_ chance for the concepts to bed in before we use them as part of our exploratory work with the InsideAirbnb sample.\n",
    "\n",
    "##### A Dictionary of Lists to the Rescue\n",
    "\n",
    "Remember, if we don't really care about column order (and why would we, on one level?), then a dictionary of lists would be a nice way to handle things. And why should we care about column order? With our CSV files above we already saw what a pain it was to fix things when the layout of the columns changed from one data set to the next. If, instead, we can just reference the 'Description' column in the data set then it doesn't matter where that column actually is. Why is that? \n",
    "\n",
    "Well, here are four rows of 'data' for city sizes organised by _row_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greater London, Greater Manchester, West Midlands\n"
     ]
    }
   ],
   "source": [
    "myData = [\n",
    "    ['id', 'Name', 'Rank', 'Longitude', 'Latitude', 'Population'], \n",
    "    ['1', 'Greater London', '1', '-18162.92767', '6711153.709', '9787426'], \n",
    "    ['2', 'Greater Manchester', '2', '-251761.802', '7073067.458', '2553379'], \n",
    "    ['3', 'West Midlands', '3', '-210635.2396', '6878950.083', '2440986']\n",
    "]\n",
    "\n",
    "# What cities are in the data set?\n",
    "col = myData[0].index('Name')\n",
    "cities = []\n",
    "for i in range(1,len(myData)):\n",
    "    cities.append(myData[i][col])\n",
    "print(\", \".join(cities))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare that code to how it works as a dictionary of lists organised by _column_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greater London, Greater Manchester, Birmingham, Edinburgh, Inverness, Lerwick\n"
     ]
    }
   ],
   "source": [
    "myData = {\n",
    "    'id'         : [0, 1, 2, 3, 4, 5],\n",
    "    'Name'       : ['Greater London', 'Greater Manchester', 'Birmingham','Edinburgh','Inverness','Lerwick'],\n",
    "    'Rank'       : [1, 2, 3, 4, 5, 6],\n",
    "    'Longitude'  : [-0.128, -2.245, -1.903, -3.189, -4.223, -1.145],\n",
    "    'Latitude'   : [51.507, 53.479, 52.480, 55.953, 57.478, 60.155],\n",
    "    'Population' : [9787426, 2705000, 1141816, 901455, 70000, 6958],\n",
    "}\n",
    "\n",
    "# What cities are in the data set?\n",
    "print(\", \".join(myData['Name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**See how even basic questions like \"Is Edinburgh in our list of data?\" are suddenly easy to answer?** <br> We no longer need to loop over the entire data set in order to find one data point. In addition, we know that everything in the 'Name' column will be a string, and that everything in the 'Longitude' column is a float, while the 'Population' column contains integers. So that's made life easier already. But let's test this out and see how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at what you can do with this... but first we need to import one _more_ package that you're going to see a _lot_ over the rest of term: `numpy` (Numerical Python), which is used _so_ much that most people simply refer to it as `np`. This is a _huge_ package in terms of features, but right now we're interested only in the basic arithmatic functions: `mean`, `max`, and `min`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a _lot_ of content to process in the code below, so do _not_ rush blindly on if it is confusing. \n",
    "\n",
    "<div style=\"border: dotted 1px rgb(156,121,26); padding: 10px; margin: 5px; background-color: rgb(255,236,184)\"><i>Stop!</i>: Look closely at what is going on. Try pulling it apart into pieces and then reassembling it. Start with the bits that you understand and then <i>add</i> complexity.</div>\n",
    "\n",
    "We'll go through each one in turn, but they nearly all work in the same way and the really key thing is that you'll notice that we no longer have any loops (which are slow) just `index` or `np.<function>` (which is _very_ fast). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Population of Manchester\n",
    "\n",
    "The code can look pretty daunting, so let's break it down into parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manchester's population is 2705000\n"
     ]
    }
   ],
   "source": [
    "city = 'Greater Manchester'\n",
    "pop = myData[\"Population\"][ myData['Name'].index(city) ]\n",
    "print(f\"Manchester's population is {pop}\") # Notice how 'f-strings' work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that this is a dictionary-of-lists (DoL). So:\n",
    "```python\n",
    "myData['Population']    # Returns a list of population values\n",
    "myData['Population'][0] # Returns the first element of that list\n",
    "```\n",
    "Does **that part** make sense?\n",
    "\n",
    "---\n",
    "\n",
    "Now, to the second part, we know that Manchester is at index position 1 in the list, but we don't want to hard-code this for every city, so we need to replace `0` with code that will look up the index of a city, and we can only get that my looking in `myData['Name']`:\n",
    "```python\n",
    "myData['Name'].index('Manchester')\n",
    "```\n",
    "\n",
    "Here we look in the dictionary for the key `Name` and find that that's _also_ a list (`['London','Manchester',...]`). All we're doing here is ask Python to find the index of 'Manchester' for us in that list. \n",
    "\n",
    "And `myData['Name'].index('Manchester')` gives us back a `1`, so _instead_ of just writing in a `1` into `myData['Population'][1]` we can replace `1` with `myData['Name'].index('Manchester')`! Notice the complete _absence_ of a for loop?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Easternmost City\n",
    "\n",
    "Because we are dealing with numeric values now we can also do useful things much more quickly like finding the first part of, say, a _bounding box_ (the East value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The easternmost city is: Greater London\n"
     ]
    }
   ],
   "source": [
    "city = myData['Name'][ myData['Longitude'].index( max(myData[\"Longitude\"]) ) ]\n",
    "print(f\"The easternmost city is: {city}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we need to break this down into parts in order to understand it:\n",
    "1. We need to find the maximum _value_ of the longitude in the data set.\n",
    "2. We need to find the _index_ of this value.\n",
    "3. We use that index value to look up the name of the city.\n",
    "\n",
    "So, the pieces in code... \n",
    "```python\n",
    "myData['Longitude']      # The longitude data values\n",
    "myData['Longitude'][0]   # The first element of the list\n",
    "max(myData['Longitude']) # The maximum value in the list\n",
    "myData['Longitude'].index(...) # Search for a value in the list\n",
    "```\n",
    "Does **that part** make sense?\n",
    "\n",
    "---\n",
    "We can then think our way through this as we might with a maths equation and substitution:\n",
    "```python\n",
    "myData['Longitude'].index( max(myData['Longitude']) ) # The index of the maximum value of the list\n",
    "myData['Name'][0] # The first element in the city list\n",
    "\n",
    "# You can use whitespace to make this more legible\n",
    "myData['Name'][\n",
    "    myData['Longitude'].index( \n",
    "        max(myData['Longitude']) \n",
    "    )\n",
    "]\n",
    "\n",
    "# Or, once you're more comfortable with code:\n",
    "city = myData['Name'][ myData['Longitude'].index( max(myData['Longitude']) ) ]\n",
    "```\n",
    "Does **that part** make sense?\n",
    "\n",
    "---\n",
    "\n",
    "So to explain this in three steps, what we're doing is:\n",
    "* Finding the maximum value in the Longitude column (we know there must be one, but we don't know what it is!),\n",
    "* Finding the index (position) of that maximum value in the Longitude column (now that we know what the value is!),\n",
    "* Using that index to read a value out of the Name column.\n",
    "\n",
    "I _am_ a geek, but that's pretty cool, right? In one line of code we managed to quickly find out where the data we needed was even though it involved three discrete steps. Think about how much work you'd have to do if you were still thinking in _rows_, not _columns_!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Location of Lerwick\n",
    "\n",
    "This is 'just' variations on a theme since we're still using the same concepts of `index` and lists, what makes it hard is that there looks to be a _lot_ of code on one line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The town of Lerwick can be found at 1.145ÂºW, 60.155ÂºN\n"
     ]
    }
   ],
   "source": [
    "city = \"Lerwick\"\n",
    "print(f\"The town of {city} can be found at \" + \n",
    "      f\"{abs(myData['Longitude'][myData['Name'].index(city)])}ÂºW, {myData['Latitude'][myData['Name'].index(city)]}ÂºN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But always remember that you can rewrite this using whitespace and concatentation to make it easier for a human to read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The town of Lerwick can be found at 1.145ÂºW, 60.155ÂºN\n"
     ]
    }
   ],
   "source": [
    "city = \"Lerwick\"\n",
    "print(f\"The town of {city} can be found at \" + \n",
    "      f\"{abs(myData['Longitude'][myData['Name'].index(city)])}ÂºW, \" +\n",
    "      f\"{myData['Latitude'][myData['Name'].index(city)]}ÂºN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you could even work it out this way first and _then_ combine the code as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The town of Lerwick can be found at 1.145ÂºW, 60.155ÂºN\n"
     ]
    }
   ],
   "source": [
    "city = \"Lerwick\"\n",
    "lat  = abs(\n",
    "    myData['Longitude'][\n",
    "        myData['Name'].index(city)\n",
    "    ]\n",
    ")\n",
    "lon  = myData['Latitude'][\n",
    "    myData['Name'].index(city)\n",
    "]\n",
    "\n",
    "print(f\"The town of {city} can be found at \" + \n",
    "      f\"{lat}ÂºW, \" +\n",
    "      f\"{lon}ÂºN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that have a `+` at the *end of the line* tells Python that it should carry on reading to the next line as part of the same command. That's a handy way to make your code a little easier to read! Same goes withg formatting a list: if it's getting a little long then you can *also* continue a line using a `,`!\n",
    "\n",
    "##### Recap of f-Strings\n",
    "\n",
    "In case you're rusty on how f-strings (`f\"<some text here>\"`) work, the first one will help you to make sense of the second: f-strings allow you to 'interpolate' code directly into a string rather than having to have lots of `str(x) + \" some text \" + str(y)`. You can write `f\"{x} some text {y}\"` and Python will automatically replace `{x}` with the _value of `x`_ and `{y}` with the _value of `y`_. \n",
    "\n",
    "So `f\"The town of {city} can be found at \"` becomes `f\"The town of Lerwick can be found at \"` because `{city}` is replaced by the value of the variable `city`. This makes for code that is easier for humans to read and so I'd consider that a good thing.\n",
    "\n",
    "##### Breaking it Down (Again)\n",
    "\n",
    "The second f-string _looks_ hard because there's a _lot_ of code there. But, again, if we start with what we recognise that it gets just a little bit more manageable... Also, it stands to reason that the only difference between the two outputs is that one asks for the 'Longitude' and the other for the 'Latitude'. So if you can make sense of one you have _automatically_ made sense of the other and don't need to work it all out.\n",
    "\n",
    "Let's start with a part that you might recognise:\n",
    "```python\n",
    "myData['Name'].index(city)\n",
    "```\n",
    "Does **that part** make sense?\n",
    "\n",
    "---\n",
    "\n",
    "You've _got_ this. This is just asking Python to work out the index of Lerwick (because `city = 'Lerwick'`). So it's a number. 5 in this case. And we can then think, 'OK so what does this return:\n",
    "```python \n",
    "myData['Longitude'][5]\n",
    "```\n",
    "And the answer is `-1.145`. That's the Longitude of Lerwick! There's just _one_ last thing: notice that we're talking about degrees West here. So the answer isn't a negative (because negative West degrees would be _East_!), it's the _absolute_ value. And that is the final piece of the puzzle: `abs(...)` gives us the absolute value of a number!\n",
    "\n",
    "Does **that part** make sense?\n",
    "\n",
    "---\n",
    "\n",
    "You could have [found `abs` yourself using Google](https://lmgtfy.app/?q=absolute+value+python)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Average City Size\n",
    "\n",
    "Here we're going to 'cheat' a little bit: rather than writing our own function, we're going to import a package and use someone _else's_ function. The `numpy` package contains a _lot_ of useful functions that we can call on (if you don't believe me, add \"`dir(np)`\" on a new line after the `import` statement), and one of them calculates the average of a list or array of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean population is: 2435442.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mean = np.mean(myData[\"Population\"])\n",
    "print(f\"The mean population is: {mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You _could_ also write this like:\n",
    "```python\n",
    "print(f\"The mean population is: {np.mean(myData['Population']}\")\n",
    "```\n",
    "There's no 'right' way here to write your code: putting it all on one line and not saving it to a temporary variable called 'mean' is slightly faster, but if you were going to use the mean to do other things (e.g. standardise the data) then it is a bit more clear what you're doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardising City Sizes\n",
    "\n",
    "To give you a sense of how scaleable this approach to data is, check out this neat little trick for working out z-scores for cities sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City distribution has sample mean 2435442.5 and sample standard deviation of 3406947.93.\n"
     ]
    }
   ],
   "source": [
    "# Use numpy functions to calculate mean and standard deviation\n",
    "mean = np.mean(myData['Population'])\n",
    "std  = np.std(myData['Population'])\n",
    "print(f\"City distribution has sample mean {mean} and sample standard deviation of {std:7.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy` gives us a way to calculate the mean and standard deviation _quickly_ and without having to reinvent the wheel. The other potentially new thing here is `{std:7.2f}`. This is about [string formatting](https://www.w3schools.com/python/ref_string_format.asp) and the main thing to recognise is that this means 'format this float with 7 digits to the left of the left of the decmial and 2 digits to the right'. The link I've provided uses the slightly older approach of `<str>.format()` but the formatting approach is the same.\n",
    "\n",
    "Does **that part** make sense?\n",
    "\n",
    "---\n",
    "\n",
    "Now we're going to see how the code `[x for x in list]` gives us a way to apply an operation (converting to string, subtracting a value, etc.) to every item in a list without writing out a full for loop. This basically gives us a one-line way to avoid writing:\n",
    "```python\n",
    "rs = []\n",
    "for x in myData['Population']:\n",
    "    rs.append((x-mean)/std)\n",
    "```\n",
    "So here code in the `for` loop is applied and the result automatically added to the output list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.1579383252868527, 0.0791199354729932, -0.3797024575689938, -0.45025269939207097, -0.6942995760276591, -0.7128035277711219]\n"
     ]
    }
   ],
   "source": [
    "rs = [(x - mean)/std for x in myData['Population']]\n",
    "myData['Std. Population'] = rs\n",
    "print(myData['Std. Population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should output:\n",
    "```\n",
    "[2.1579383252868527, 0.0791199354729932, -0.3797024575689938, -0.45025269939207097, -0.6942995760276591, -0.7128035277711219]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City name: Greater London, Greater Manchester, Birmingham, Edinburgh, Inverness, Lerwick\n",
      "Raw population: 9787426, 2705000, 1141816, 901455, 70000, 6958\n",
      "Standardised population: 2.158, 0.079, -0.380, -0.450, -0.694, -0.713\n"
     ]
    }
   ],
   "source": [
    "print(\"City name: \" + \", \".join( myData['Name'] ))\n",
    "print(\"Raw population: \" + \", \".join( [str(x) for x in myData['Population']] ))\n",
    "print(\"Standardised population: \" + \", \".join( [f\"{x:4.3f}\" for x in myData['Std. Population']] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where our new approach really comes into its own: because all of the population data is in one place (a.k.a. a _series_ or column), we can just throw the whole list into the `np.mean` function rather than having to use all of those convoluted loops and counters. Simples, right? \n",
    "\n",
    "No, not _simple_ at all conceptually, but we've come up with a way to _make_ it simple _as code_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brain Teaser\n",
    "\n",
    "Why not have a stab at writing the code to print out the _4th most populous_ city? This can _still_ be done on one line, though you might want to start by breaking the problem down:\n",
    "1. How do I find the _4th_ largest value in a list?\n",
    "2. How do I find the _index_ of the 4th largest value in a list?\n",
    "3. How do I use that to look up the name associated with that index?\n",
    "\n",
    "You've already done \\#2 and \\#3 above so you've _solved_ that problem. If you can solve \\#1 then the rest should fall into place.\n",
    "\n",
    "<div style=\"border: dotted 1px green; padding: 10px; margin: 5px; background-color: rgb(249,255,249);\"><i>Hint</i>: you don't want to use <tt>&lt;list&gt;.sort()</tt> because that will sort your data <i>in place</i> and break the link between the indexes across the 'columns'; you want to research the function <tt>sorted(&lt;list&gt;)</tt> where <tt>&lt;list&gt;</tt> is the variable that holds your data and `sorted(...)` just returns whatever you pass it in a sorted order <i>without</i> changing the original list. You'll see why this matters if you get the answer... otherwise, wait a few days for the answers to post.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9787426, 2705000, 1141816, 901455, 70000, 6958]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(myData['Population'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901455\n",
      "3\n",
      "The fourth most populous city is: Edinburgh\n"
     ]
    }
   ],
   "source": [
    "# Print out the name of the 4th most populous city-region\n",
    "\n",
    "# Find the fourth largest value\n",
    "fourth = sorted(myData['Population'], reverse=True)[3]\n",
    "print(fourth)\n",
    "\n",
    "# Find the index of the fourth largest value\n",
    "idx = myData['Population'].index(fourth)\n",
    "print(idx)\n",
    "\n",
    "# Find the city associated with that value\n",
    "city = myData['Name'][idx]\n",
    "\n",
    "# And output\n",
    "print(\"The fourth most populous city is: \" + str(city))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is Edinburgh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recap!\n",
    "\n",
    "So the _really_ clever bit in all of this isn't switching from a list-of-lists to a dictionary-of-lists, it's recognising that the dictionary-of-lists is a _better_ way to work _with_ the data that we're trying to analyse and that that there are useful functions that we can exploit to do the heavy lifting for us. Simply by changing the way that we stored the data in a 'data structure' (i.e. complex arrangement of lists, dictionaries, and variables) we were able to do away with lots of for loops and counters and conditions, and reduce many difficult operations to something that could be done on one line! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Creating a Set of Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start trying to put this all together by creating a a set of functions that will help us to:\n",
    "\n",
    "1. Download a file from a URL (checking if it has already _been_ downloaded to save bandwidth).\n",
    "2. Parse it as a CSV file and...\n",
    "3. Convert it to a Dictionary-of-Lists\n",
    "4.Perform some simple calculations using the resulting data.\n",
    "\n",
    "To be honest, there's not going to be much about writing our _own_ objects here, but we will be making use of them and, conceptually, an understanding of objects and classes is going to be super-useful for understanding what we're doing in the remainder of the term!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.1: Start from Existing Code\n",
    "\n",
    "First, let's be sensibly lazy--we've already written code to read a file ([2020-08-24-sample-listings.csv](https://raw.githubusercontent.com/jreades/fsds/master/data/2020-08-24-sample-listings-simple.csv)) from the Internet and turn it into a list of lists. So I've copy+pasted that into the code block below since we're going to start from this point; however, just to help you check your own understanding, I've removed a few bits and replacement with `??`. Sorry. ðŸ˜ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urlData has 101 rows and 19 columns.\n",
      "['40373464', 'Modern, Small Double Private Room']\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import csv\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jreades/fsds/master/data/2020-08-24-sample-listings-simple.csv\"\n",
    "\n",
    "urlData = [] # Somewhere to store the data\n",
    "\n",
    "response = urlopen(url) #Â Get the data using the urlopen function\n",
    "csvfile  = csv.reader(response.read().decode('utf-8').splitlines()) # Pass it over to the reader\n",
    "\n",
    "for row in csvfile:\n",
    "    urlData.append(row)\n",
    "\n",
    "print(\"urlData has \" + str(len(urlData)) + \" rows and \" + str(len(urlData[0])) + \" columns.\")\n",
    "print(urlData[-1][:2]) # Check it worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get `urlData has 101 rows and 19 columns.` and a row that looks like this: `['40373464', 'Modern, Small Double Private Room']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.2: Getting Organised\n",
    "\n",
    "Let's take the code above and modify it so that it is:\n",
    "\n",
    "1. A function that takes two arguments: a URL; and a destination filename.\n",
    "2. Implemented as a function that checks if a file exists already before downloading it again.\n",
    "\n",
    "You will find that the `os` module helps here because of the `path` function. And you will [need to Google](https://lmgtfy.app/?q=check+if+file+exists+python) how to test if a file exists. I would normally select a StackOverflow link in the results list over anything else because there will normally be an _explanation_ included of why a particular answer is a 'good one'. I also look at which answers got the most votes (not always the same as the one that was the 'accepted answer'). In this particular case, I also found [this answer](https://careerkarma.com/blog/python-check-if-file-exists/) useful.\n",
    "\n",
    "--- \n",
    "\n",
    "I would start by setting my inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/2020-08-24-sample-listings-simple.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#url = \"https://raw.githubusercontent.com/jreades/fsds/master/data/2020-08-24-sample-listings-simple.csv\"\n",
    "\n",
    "url= \"https://raw.githubusercontent.com/jreades/fsds/master/data/2020-08-24-sample-listings-simple.csv\"\n",
    "out = os.path.join('data','2020-08-24-sample-listings-simple.csv')\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.3: Sketching Out a Function\n",
    "\n",
    "Then I would sketch out how my function will work using comments. And the simplest thing to start with is checking whether the file has already been downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found data/2020-08-24-sample-listings-simple.csv!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import csv\n",
    "\n",
    "def get_url(src, dest):\n",
    "    \n",
    "    # Check if dest does *not* exist -- that\n",
    "    # would mean we had to download it!\n",
    "    if not os.path.isfile(dest):\n",
    "        print(f\"{dest} not found!\")\n",
    "    else:\n",
    "        print(f\"Found {dest}!\")\n",
    "        \n",
    "get_url(url, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.4: Fleshing Out a Function \n",
    "\n",
    "I would then flesh out the code that checks if the data has been downloaded and ensure that both my if and else 'branches' return a list that I could then read using the CSV library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found data/2020-08-24-sample-listings-simple.csv locally!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def get_url(src, dest):\n",
    "    \n",
    "    # Check if dest does *not* exist -- that\n",
    "    # would mean we had to download it!\n",
    "    if not os.path.isfile(dest):\n",
    "        print(f\"{dest} not found, downloading!\")\n",
    "        \n",
    "        #Â Get the data using the urlopen function\n",
    "        response = urlopen(src) \n",
    "        filedata = response.read().decode('utf-8')\n",
    "        \n",
    "        # Extract the part of the dest(ination) that is *not*\n",
    "        # the actual filename--have a look at how \n",
    "        # os.path.split works using `help(os.path.split)`\n",
    "        path = list(os.path.split(dest)[:-1])\n",
    "        \n",
    "        # Create any missing directories in dest(ination) path\n",
    "        # -- os.path.join is the reverse of split (as you saw above)\n",
    "        # but it doesn't work with lists... so I had to google how \n",
    "        # to use the 'splat' operator! os.makedirs creates missing \n",
    "        # directories in a path automatically.\n",
    "        if len(path) >= 1 and path[0] != '':\n",
    "            os.makedirs(os.path.join(*path), exist_ok=True)\n",
    "        \n",
    "        # This would be how to write data to a file, \n",
    "        # but what should we write?\n",
    "        with open(dest, 'w') as f:\n",
    "            f.write(filedata)\n",
    "            \n",
    "    else:\n",
    "        print(f\"Found {dest} locally!\")\n",
    "    \n",
    "    with open(dest, 'r', encoding='utf-8') as f:\n",
    "        return f.read().splitlines()\n",
    "        \n",
    "# Using the `return contents` line we make it easy to \n",
    "# see what our function is up to.\n",
    "c = get_url(url, out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: dotted 1px rgb(156,121,26); padding: 10px; margin: 5px; background-color: rgb(255,236,184)\"><i>Stop!</i> Notice that we don't try to check if the data file contains any useful data! So if you download or create an empty file while testing, you won't necessarily get an error until you try to turn it into data afterwards!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.5: Read a CSV file into a LoL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've taken care of whether or not the file has already been downloaded, we can focus on the next part of the problem! We have looked at code like this before in the Live sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Notice that it doesn't make sense to use `dest` as the \n",
    "# parameter name here because we always read *from* a data\n",
    "# source. Your names can be whatever you want, but they \n",
    "# should be logical wherever possible!\n",
    "def to_lol(lst):\n",
    "    \n",
    "    # Rest of code to read file and convert it goes here\n",
    "    csvdata = []\n",
    "    \n",
    "    # This is the same code that you used last week, but \n",
    "    # you'll have to rename some vars to get things to\n",
    "    # work for you here.\n",
    "    csvfile  = csv.reader(urlopen(url).read().decode('utf-8').splitlines())\n",
    "    for row in csvfile:              \n",
    "        csvdata.append( row )\n",
    "    \n",
    "    # Return list of lists\n",
    "    return csvdata\n",
    "        \n",
    "# Save the CSV-LoL to a new variable\n",
    "clol = to_lol(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoL has 101 rows and 19 columns.\n",
      "['id', 'name']\n",
      "['40373464', 'Modern, Small Double Private Room']\n"
     ]
    }
   ],
   "source": [
    "print(f\"LoL has {len(clol)} rows and {len(clol[0])} columns.\")\n",
    "print(clol[0][:2])\n",
    "print(clol[-1][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get: \n",
    "```\n",
    "LoL has 101 rows and 19 columns.\n",
    "['id', 'name']\n",
    "['40373464', 'Modern, Small Double Private Room']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.6: Convert a LoL to a DoL\n",
    "\n",
    "We're going to assume that the first row of our LoL is always a _header_ (i.e. list of column names). If it's not then this code is going to have problems. A _robust_ function would allow us to specify column names when we create the data structure, but let's not get caught up in that level of detail just yet.\n",
    "\n",
    "Have a look at Task 2.3 from the Live Coding session to see how to fill this in... Notice that I've also, for the first time used the docstring support offered by Python. Once this function is working you'll be able to use `help(to_dol)` and get back the docstring help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': ['25339003', '40259218', '20097666', '40868766', '29649371', '6650370', '42405264', '13501585', '36162322', '20631005', '32175015', '38406649', '21315952', '16361918', '39556787', '26542484', '21744434', '4059945', '5345295', '44257873', '15768207', '1683278', '24386203', '39349912', '29726372', '34713135', '424511', '2465026', '4743124', '25134847', '39437321', '35825237', '1474317', '28652501', '6868537', '726669', '20821143', '10408740', '14309812', '27866278', '40885187', '28394803', '8680525', '13433229', '37215315', '39432597', '42843489', '42337868', '25451074', '39817130', '41950973', '42513545', '27026005', '1114488', '32253983', '39911815', '39225196', '18789292', '13289226', '29502574', '20893587', '23523880', '10880757', '44069559', '34556153', '15307633', '12263797', '32347496', '668819', '29896303', '13663264', '40657332', '29230752', '32842985', '1043759', '22987867', '11707553', '20238937', '42106572', '31814561', '12195983', '41276640', '19036976', '19246652', '41665916', '29752790', '38222036', '37427933', '20916454', '29273072', '8948392', '38322409', '24146292', '21996251', '22681593', '33923856', '18734228', '41376268', '34560337', '40373464'], 'name': ['An Amazing 4Bedroom Home, Central London, Sleeps12', 'Large Double Room - Maida Vale', 'Zone 1 : Spacious single bedroom in Bayswater', 'Large Smart Room 20 minutes walk to Big Ben', 'Large Notting Hill 2BR near Portobello Rd', 'Quiet flat with private garden in Barons Court', \"Superhost's Lux 3B Luxury Flat- 397 5-Star Reviews\", 'Lovely and bright garden flat', 'Covent Garden Private Room with Shared Living Room', 'Double Room with private bathroom', 'Warm 1BR garden flat in leafy Hampstead (Veeve)', 'Single  in NW2', 'single bedroom near heathrow london free parking', 'Luxury New Apartment with Spa and Pool', 'Stylish Family Maisonette in Vibrant South London', 'Single/double room facing garden', 'Spaceous 2 bed house in Battersea / Clapham', 'Fitzrovia, Oxford circus, Soho', 'Balham - Beautiful Room', '133R6 Ensuite modern, quiet room, 20min to center', 'Large double bedroom PLUS full use of lovely house', 'Chelsea - Luxury flat with terrace', 'London room with good links into town', 'Fun, Stylish 5-Bed Family House in Kensal Green', 'Lovely 2 BEDROOM flat, heart of Fulham(sleeps 4-5)', 'DBL ROOM NEAR WHITECHAPEL ( E3 5DF)', 'House to rent in Olimpics', 'Luxury 2-Bed Flat with Balcony, 15min to West End', 'Spacious, sunny room in Dalston home', 'New Modern Family Home In Uxbridge .', 'Bed in 8-Bed Mixed Dorm with Ensuite Bathroom', 'Piccadilly Line-Turnpike Lane Station', 'Shoreditch Luxury Room + en-suite', 'Sweet Home', 'Designer flat in Primrose Hill', 'Brand new studio in Victoria 11A', 'Spacious 1 bed apartment near Tower Bridge', 'Trendy 2 bedroom flat in Shoreditch', 'Eye of London by Merino', 'Hoxton / Haggerston Apartment', 'Stylish 2-Bed Garden Apartment, 1 min from Tube!', 'The Garden Studios, London SW13 - Sleeps 6.', 'Spacious flat nearby river & park', 'Separate annex in lovely area close to Wimbledon', 'Avni Kensington Hotel', '3 Bed, 20 min to Liverpool st, EAST LONDON', 'Deluxe Double Room in OYO The Greenland Hotel', 'Trendy 3BR Family Garden Home in Dalston - up to 5 guests!', 'Private room in East London', 'Cosy 1 Bedroom Apt, 8 mins to Aldgate East Station', 'Supreme Triple Studio in the heart of Baker Street', 'Spacious room in a cosy home', 'Cozy single room in Stockwell', 'Flat in Islington, Central London', 'Studio Two ArtHouse London Bridge', 'Luxurious 4-Bed House in Fulham with Terrace', 'Room 1, Kenmare, New Road Rainham, RM13 9PN', 'Light and spacious 2bed 1 bath flat!', 'I love Peckham', 'Spacious room in beautiful flat. East London!', 'Peaceful with stylish private bathroom VH', '3 Bedroom family home in West Dulwich', 'Chelsea/Fulham stylish 3Bed Terrace', 'Short let spacious double room in East London', 'Lovely double bedroom in modern house', 'Farmhouse close to London in beautiful grounds', 'Pretty one bedroom cottage in leafy london suburb', 'Beautiful Large Clean Quiet En-suit Double Room!', 'Single Room to let in Clean House', 'Clean Cosy Loft (private parking & tube)', '3bedroom Family Home minutes from Kensington Tube', 'Professionally cleaned 1 bed west London apt seconds from Fulham Broadway', 'Double room in modern chic apartment, Dalston E8', 'Modern & Bright Entire Flat 2 Rooms Old Street', 'Room in Central London Paddington', 'NEW HOME OR HOLIDAY IN LONDON - long or short term', 'Room and bathroom close to central', 'Lovely Room in Best Location', 'Luxury Apartment Canary Wharf', 'Studio 9-Camden Style- Twin beds or Superking!', 'Large Knightsbridge 2Bed 2Bath Free WiFi', 'Great Location of my flat 15mn from central london', 'Luxury Room in a Great Location.', 'Southfields Home', '4 Bedroom family house in Ilford East London', 'Comfy 1Bedroom Apartment in the heart of London', 'Luxury 2 bed 2 minutes from station', 'Private room in Dalston sleeps 3', 'Delightful Private Bedroom, 2 mins to Tube', 'Ensuite room (privat)  30 min to Central London', 'Flat in a new building, canal views', 'Close 2 Royal Arsenal, Thames Clipper City Airport', 'Large Double in a 2-bed garden flat in Ally Pally', 'Cosy room in very good location', 'Charming house with garden in the heart of Peckham', 'King-size bed in stylish,  peaceful artistâ€™s flat', 'Top floor 1 bed apartment with spectacular views', '(8DH) Dreams Unlimited - Hounslow/Heathrow', 'Portobello Mews House for 8 guests+free parking', 'Modern, Small Double Private Room'], 'host_id': ['191329110', '302720259', '39710946', '300905210', '2165973', '3440336', '28381203', '42097052', '8033408', '42411592', '137094377', '192355301', '154284698', '4221972', '39738485', '5160322', '121905649', '21057314', '27697836', '190233321', '26527466', '2036946', '184057890', '27572615', '26816558', '45985758', '2110389', '5404325', '12747127', '189965061', '302707533', '29918926', '8896463', '216190599', '338851', '580475', '148641390', '7807701', '5352830', '28822248', '27572615', '148114998', '43582898', '28695363', '280178840', '302880841', '337666693', '6703533', '104508239', '96569915', '178407503', '338565890', '188332446', '6116528', '241166714', '27572615', '300916979', '39496502', '7851320', '28936999', '68561737', '17931388', '56374442', '97529920', '27397891', '97494946', '66047258', '131528337', '3381734', '107260536', '37056489', '258580205', '1951049', '49413779', '5747106', '168407586', '20351987', '94603761', '297690387', '30629100', '31066062', '324177252', '132853716', '4037050', '92973657', '201263915', '204530689', '82448401', '150322962', '220537638', '2153966', '81937925', '5047300', '58077301', '11875492', '2594564', '5065286', '142206238', '47237234', '139052118'], 'host_name': ['Emily', 'Mantas', 'Thanyawan', 'Nadia', 'Emily & Kirsty', 'Emily', 'Emrah', 'Tommaso', 'Che', 'Pascale', 'Veeve', 'Nilgun', 'Mark', 'Emile', 'Holly', 'Dan', 'James', 'Vilma', 'Georgie', 'Santa', 'Michael', 'Francesco', 'Emma', 'Emily', 'Gemma', 'Md', 'Giray', 'Gabriele', 'Shu Han', 'Amrik', 'Safestay', 'Jack', 'Rich', 'Nick', 'Giorgia', 'Alessandro', 'Andrew', 'Joseph', 'Caio & Louise', 'Caite', 'Emily', 'Lurdes', 'Julianne', 'Vincent', 'Thelma', 'Dean', 'OYO The Greenland Hotel', 'Jessica', 'Agata', 'Tee & Jay', 'Nox Hotels', 'Dila', 'Mario And Elena', 'Richard', 'Michael', 'Emily', 'Jude', 'Frances', 'Tanya', 'Anisa', 'Veronica', 'Allan', 'Christian', 'Chiara', 'Erika', 'Katie', 'Anne', 'Njabulo', 'Jane', 'Marlon', 'Will', 'Sverrir & Vesta', 'Claudia', 'Olivia', 'Salwa', 'Genna', 'Lu', 'Moritz', 'Flexystays', 'Gary', 'Robert', 'Rhita', 'Joey', 'Ben', 'Biodun', 'Claire', 'Tan', 'Maureen', 'Diyala', 'Marita', 'Michael', 'Neil', 'Kat', 'Sylwia', 'Anna Rose', 'Adit', 'Dom', 'Rajesh', 'Marcus', 'Leon'], 'host_since': ['2018-05-24', '2019-10-16', '2015-07-27', '2019-10-08', '2012-04-18', '2012-09-01', '2015-02-26', '2015-08-21', '2013-08-08', '2015-08-24', '2017-06-26', '2018-05-29', '2017-10-12', '2012-11-23', '2015-07-27', '2013-02-20', '2017-03-21', '2014-09-07', '2015-02-13', '2018-05-18', '2015-01-22', '2012-03-30', '2018-04-13', '2015-02-11', '2015-01-27', '2015-10-07', '2012-04-10', '2013-03-10', '2014-03-03', '2018-05-16', '2019-10-16', '2015-03-24', '2013-09-17', '2018-09-19', '2011-01-07', '2011-05-11', '2017-09-01', '2013-07-29', '2013-03-06', '2015-03-05', '2015-02-11', '2017-08-28', '2015-09-07', '2015-03-03', '2019-07-28', '2019-10-17', '2020-02-20', '2013-06-02', '2016-11-20', '2016-09-24', '2018-03-14', '2020-02-24', '2018-05-07', '2013-04-27', '2019-02-05', '2015-02-11', '2019-10-08', '2015-07-25', '2013-07-31', '2015-03-07', '2016-04-23', '2014-07-10', '2016-01-27', '2016-10-01', '2015-02-08', '2016-10-01', '2016-04-06', '2017-05-22', '2012-08-26', '2016-12-14', '2015-06-29', '2019-04-28', '2012-03-18', '2015-11-19', '2013-04-03', '2018-01-17', '2014-08-21', '2016-09-11', '2019-09-24', '2015-04-05', '2015-04-12', '2020-01-04', '2017-05-31', '2012-11-01', '2016-09-01', '2018-07-10', '2018-07-23', '2016-07-08', '2017-09-12', '2018-10-14', '2012-04-16', '2016-07-05', '2013-02-11', '2016-02-09', '2014-02-02', '2012-06-10', '2013-02-12', '2017-07-24', '2015-10-23', '2017-07-07'], 'latitude': ['51.52865', '51.52594000000001', '51.51743', '51.48951', '51.52007', '51.48863', '51.56214', '51.55646', '51.51228', '51.47273', '51.547', '51.56214', '51.43955', '51.53099', '51.42263', '51.46852', '51.46597', '51.51528', '51.43855', '51.5166', '51.43917', '51.49193', '51.66791', '51.53391', '51.47765', '51.52908', '51.51367', '51.47604000000001', '51.55571', '51.51895', '51.49142', '51.59264', '51.5251', '51.43713', '51.54192000000001', '51.49142', '51.49344', '51.54198', '51.51588', '51.53629', '51.49086', '51.47749', '51.48067', '51.39508', '51.49521', '51.55014', '51.4787', '51.55408', '51.54781', '51.51466', '51.52378', '51.58043', '51.47356', '51.5489', '51.50297', '51.4776', '51.51981', '51.47302', '51.472', '51.53121', '51.4367', '51.43119', '51.47139', '51.55423', '51.48087', '51.44118', '51.41899', '51.58425', '51.55851', '51.41674', '51.49228', '51.48087', '51.54222', '51.53159', '51.52146', '51.47473', '51.42829', '51.52749', '51.51376', '51.38298', '51.49425', '51.55201', '51.552', '51.4514', '51.5492', '51.51461', '51.51704', '51.55341', '51.49003', '51.48769', '51.53855', '51.49341', '51.59852', '51.55031', '51.46763', '51.61141', '51.48843', '51.47631', '51.51818', '51.46497'], 'longitude': ['-0.19998', '-0.18909', '-0.18702', '-0.11812', '-0.20328', '-0.21495', '-0.23681', '-0.10387', '-0.12788', '-0.04183', '-0.17704', '-0.22505', '-0.40618', '-0.09709', '-0.16713', '-0.09454', '-0.16261', '-0.14195', '-0.14878', '-0.25064000000000003', '0.06681000000000001', '-0.16441', '-0.0271', '-0.23132', '-0.1942', '-0.03751', '0.04656', '-0.11684', '-0.07282999999999999', '-0.47724', '-0.09879', '-0.09536', '-0.08163', '-0.12679', '-0.16419', '-0.13955', '-0.07324', '-0.07958', '-0.11234', '-0.0751', '-0.19211', '-0.24351', '-0.09683', '-0.21914', '-0.14072', '0.01832', '0.02016', '-0.07767', '-0.06857', '-0.06433', '-0.1604', '-0.04007', '-0.12536', '-0.10863', '-0.08542999999999999', '-0.19178', '0.2053', '-0.12635', '-0.07514', '-0.05731', '-0.16719', '-0.08983', '-0.18524', '-0.07896', '-0.33142', '0.15287', '-0.04507', '-0.17264000000000002', '-0.00967', '-0.17246', '-0.20883', '-0.1967', '-0.0703', '-0.08668', '-0.18633', '-0.06875', '-0.15175', '-0.11687', '-0.02139', '-0.08001', '-0.16382', '-0.11021', '-0.18813', '-0.2021', '0.08101', '-0.12717', '-0.07182999999999999', '-0.06899', '-0.19176', '0.11406', '-0.07819', '0.0818', '-0.12318', '0.00373', '-0.07021000000000001', '-0.12465', '-0.21288', '-0.34523000000000004', '-0.20678', '-0.17807'], 'property_type': ['Entire house', 'Private room in apartment', 'Private room in apartment', 'Private room in apartment', 'Entire apartment', 'Entire apartment', 'Entire apartment', 'Entire apartment', 'Room in serviced apartment', 'Private room in house', 'Entire apartment', 'Private room in house', 'Private room', 'Entire apartment', 'Entire apartment', 'Private room in apartment', 'Entire house', 'Entire apartment', 'Private room in house', 'Private room in house', 'Private room in house', 'Entire apartment', 'Private room in house', 'Entire house', 'Entire apartment', 'Private room in house', 'Entire house', 'Entire apartment', 'Private room in house', 'Entire house', 'Shared room in hostel', 'Private room in house', 'Private room in apartment', 'Private room in apartment', 'Entire apartment', 'Entire apartment', 'Entire apartment', 'Entire apartment', 'Entire apartment', 'Entire apartment', 'Entire apartment', 'Private room in guesthouse', 'Private room in apartment', 'Entire guest suite', 'Entire house', 'Entire house', 'Room in boutique hotel', 'Entire house', 'Private room in apartment', 'Entire apartment', 'Private room in serviced apartment', 'Private room in house', 'Private room in apartment', 'Entire apartment', 'Private room in townhouse', 'Entire house', 'Private room in house', 'Entire apartment', 'Entire apartment', 'Private room in apartment', 'Private room in house', 'Entire house', 'Entire apartment', 'Private room in condominium', 'Private room in house', 'Entire house', 'Entire guest suite', 'Private room in apartment', 'Private room in townhouse', 'Private room in house', 'Entire apartment', 'Entire apartment', 'Private room in apartment', 'Entire apartment', 'Private room in apartment', 'Private room in house', 'Private room in apartment', 'Private room in apartment', 'Entire apartment', 'Entire apartment', 'Entire apartment', 'Private room in apartment', 'Private room in apartment', 'Entire apartment', 'Entire house', 'Entire apartment', 'Entire apartment', 'Private room in house', 'Private room in apartment', 'Private room in house', 'Entire apartment', 'Private room in house', 'Private room in apartment', 'Private room in house', 'Entire townhouse', 'Private room in apartment', 'Entire apartment', 'Entire apartment', 'Entire house', 'Private room in apartment'], 'room_type': ['Entire home/apt', 'Private room', 'Private room', 'Private room', 'Entire home/apt', 'Entire home/apt', 'Entire home/apt', 'Entire home/apt', 'Hotel room', 'Private room', 'Entire home/apt', 'Private room', 'Private room', 'Entire home/apt', 'Entire home/apt', 'Private room', 'Entire home/apt', 'Entire home/apt', 'Private room', 'Private room', 'Private room', 'Entire home/apt', 'Private room', 'Entire home/apt', 'Entire home/apt', 'Private room', 'Entire home/apt', 'Entire home/apt', 'Private room', 'Entire home/apt', 'Shared room', 'Private room', 'Private room', 'Private room', 'Entire home/apt', 'Entire home/apt', 'Entire home/apt', 'Entire home/apt', 'Entire home/apt', 'Entire home/apt', 'Entire home/apt', 'Private room', 'Private room', 'Entire home/apt', 'Entire home/apt', 'Entire home/apt', 'Private room', 'Entire home/apt', 'Private room', 'Entire home/apt', 'Private room', 'Private room', 'Private room', 'Entire home/apt', 'Private room', 'Entire home/apt', 'Private room', 'Entire home/apt', 'Entire home/apt', 'Private room', 'Private room', 'Entire home/apt', 'Entire home/apt', 'Private room', 'Private room', 'Entire home/apt', 'Entire home/apt', 'Private room', 'Private room', 'Private room', 'Entire home/apt', 'Entire home/apt', 'Private room', 'Entire home/apt', 'Private room', 'Private room', 'Private room', 'Private room', 'Entire home/apt', 'Entire home/apt', 'Entire home/apt', 'Private room', 'Private room', 'Entire home/apt', 'Entire home/apt', 'Entire home/apt', 'Entire home/apt', 'Private room', 'Private room', 'Private room', 'Entire home/apt', 'Private room', 'Private room', 'Private room', 'Entire home/apt', 'Private room', 'Entire home/apt', 'Entire home/apt', 'Entire home/apt', 'Private room'], 'accommodates': ['12', '2', '1', '2', '4', '2', '8', '6', '2', '2', '4', '1', '1', '4', '4', '2', '4', '4', '2', '1', '2', '2', '1', '9', '5', '1', '4', '5', '2', '8', '8', '1', '3', '3', '5', '2', '2', '4', '4', '2', '4', '6', '2', '2', '2', '7', '2', '5', '1', '6', '3', '2', '1', '2', '4', '10', '2', '4', '2', '1', '2', '9', '6', '1', '2', '7', '2', '2', '1', '3', '6', '3', '2', '4', '2', '2', '2', '1', '4', '2', '5', '2', '2', '5', '7', '2', '4', '3', '2', '2', '4', '1', '2', '1', '2', '2', '2', '6', '8', '1'], 'bathrooms': ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], 'bedrooms': ['4.0', '1.0', '1.0', '1.0', '2.0', '1.0', '3.0', '3.0', '1.0', '1.0', '1.0', '1.0', '1.0', '2.0', '2.0', '1.0', '2.0', '2.0', '1.0', '1.0', '1.0', '1.0', '1.0', '5.0', '2.0', '1.0', '2.0', '2.0', '1.0', '4.0', '1.0', '1.0', '1.0', '1.0', '2.0', '1.0', '1.0', '2.0', '2.0', '1.0', '2.0', '3.0', '1.0', '', '1.0', '3.0', '1.0', '3.0', '1.0', '1.0', '2.0', '1.0', '1.0', '1.0', '2.0', '4.0', '1.0', '2.0', '1.0', '1.0', '1.0', '3.0', '3.0', '1.0', '1.0', '4.0', '1.0', '1.0', '1.0', '1.0', '3.0', '1.0', '1.0', '2.0', '1.0', '1.0', '1.0', '1.0', '2.0', '', '2.0', '2.0', '1.0', '2.0', '4.0', '1.0', '2.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '2.0', '4.0', '1.0'], 'beds': ['9.0', '1.0', '1.0', '2.0', '2.0', '1.0', '6.0', '3.0', '1.0', '1.0', '1.0', '1.0', '1.0', '2.0', '3.0', '1.0', '2.0', '2.0', '1.0', '0.0', '1.0', '1.0', '1.0', '4.0', '5.0', '1.0', '1.0', '3.0', '1.0', '4.0', '8.0', '1.0', '1.0', '2.0', '4.0', '1.0', '1.0', '2.0', '2.0', '1.0', '2.0', '4.0', '1.0', '1.0', '1.0', '5.0', '1.0', '3.0', '1.0', '3.0', '2.0', '2.0', '0.0', '1.0', '2.0', '4.0', '1.0', '2.0', '1.0', '1.0', '1.0', '4.0', '3.0', '0.0', '1.0', '6.0', '1.0', '1.0', '1.0', '1.0', '4.0', '1.0', '1.0', '2.0', '2.0', '1.0', '1.0', '1.0', '2.0', '3.0', '2.0', '3.0', '2.0', '3.0', '4.0', '1.0', '2.0', '2.0', '1.0', '1.0', '2.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '2.0', '4.0', '1.0'], 'price': ['$226.00', '$41.00', '$35.00', '$55.00', '$100.00', '$68.00', '$150.00', '$110.00', '$130.00', '$45.00', '$166.00', '$29.00', '$20.00', '$150.00', '$102.00', '$29.00', '$300.00', '$203.00', '$56.00', '$30.00', '$50.00', '$230.00', '$23.00', '$413.00', '$149.00', '$32.00', '$181.00', '$199.00', '$26.00', '$150.00', '$15.00', '$25.00', '$89.00', '$30.00', '$260.00', '$76.00', '$96.00', '$148.00', '$337.00', '$95.00', '$297.00', '$170.00', '$55.00', '$59.00', '$430.00', '$110.00', '$504.00', '$175.00', '$26.00', '$85.00', '$156.71', '$26.00', '$37.00', '$55.00', '$102.00', '$798.00', '$60.00', '$120.00', '$120.00', '$50.00', '$40.00', '$98.00', '$185.00', '$25.00', '$45.00', '$250.00', '$58.00', '$45.00', '$19.00', '$49.00', '$221.00', '$104.00', '$65.00', '$95.00', '$70.00', '$30.00', '$38.00', '$35.00', '$165.00', '$46.71', '$515.00', '$55.00', '$47.00', '$85.00', '$150.00', '$65.00', '$170.00', '$16.00', '$45.00', '$25.00', '$99.00', '$25.00', '$50.00', '$17.00', '$95.00', '$50.00', '$105.00', '$142.00', '$263.00', '$38.00'], 'minimum_nights': ['2', '1', '4', '2', '3', '2', '2', '14', '2', '2', '4', '3', '3', '50', '2', '3', '1', '5', '1', '12', '2', '4', '1', '3', '1', '15', '7', '4', '1', '3', '1', '2', '1', '1', '5', '1', '3', '2', '2', '2', '3', '3', '2', '2', '1', '3', '1', '3', '1', '2', '1', '1', '2', '28', '3', '5', '1', '2', '7', '2', '3', '3', '3', '30', '2', '2', '7', '1', '1', '1', '3', '2', '1', '5', '90', '1', '2', '6', '2', '4', '3', '3', '3', '6', '3', '2', '7', '1', '1', '1', '4', '1', '1', '4', '5', '2', '3', '1', '2', '1'], 'maximum_nights': ['1125', '24', '1125', '1125', '1125', '30', '1125', '1125', '1125', '1125', '1125', '1125', '7', '1125', '365', '30', '1125', '60', '1125', '99', '21', '1125', '7', '1125', '1125', '1125', '1125', '1125', '1125', '365', '365', '45', '365', '1125', '1125', '1125', '1125', '1125', '1125', '1125', '1125', '90', '1125', '7', '1125', '1125', '1125', '1125', '1125', '90', '1125', '20', '1125', '1125', '1125', '1125', '15', '1125', '1125', '90', '14', '30', '1125', '45', '30', '1125', '1125', '30', '180', '9', '1125', '1125', '1125', '1125', '1125', '365', '7', '1125', '1125', '365', '1124', '10', '93', '20', '14', '28', '1125', '28', '14', '180', '30', '1125', '1125', '12', '30', '30', '1125', '1125', '31', '1125'], 'availability_365': ['23', '365', '0', '230', '0', '0', '365', '0', '0', '340', '246', '363', '89', '3', '0', '365', '180', '88', '365', '64', '87', '0', '83', '0', '52', '365', '0', '0', '0', '0', '237', '357', '0', '90', '329', '0', '11', '0', '356', '34', '0', '338', '0', '172', '365', '0', '336', '0', '0', '0', '2', '85', '91', '75', '327', '122', '89', '0', '33', '329', '168', '178', '0', '5', '179', '169', '305', '365', '318', '55', '338', '0', '364', '0', '365', '270', '0', '0', '170', '298', '0', '83', '364', '0', '0', '0', '0', '252', '363', '0', '268', '0', '80', '0', '0', '90', '0', '365', '52', '0'], 'number_of_reviews': ['64', '4', '0', '4', '15', '45', '0', '0', '1', '2', '0', '1', '69', '2', '1', '9', '3', '33', '16', '0', '10', '3', '0', '0', '26', '0', '0', '26', '1', '7', '0', '13', '25', '32', '11', '330', '76', '6', '32', '14', '1', '8', '1', '115', '0', '2', '0', '1', '1', '19', '0', '2', '64', '4', '31', '0', '0', '7', '2', '38', '95', '0', '22', '0', '16', '16', '33', '27', '126', '61', '153', '1', '5', '13', '185', '1', '3', '0', '5', '58', '13', '0', '50', '3', '5', '8', '1', '25', '23', '27', '3', '2', '1', '0', '28', '0', '2', '1', '13', '4'], 'calculated_host_listings_count': ['1', '5', '1', '3', '1', '1', '27', '1', '1', '2', '267', '3', '1', '4', '1', '1', '1', '1', '1', '10', '2', '15', '1', '169', '2', '1', '1', '2', '1', '1', '9', '1', '1', '1', '2', '41', '1', '1', '7', '1', '169', '2', '1', '1', '1', '1', '3', '1', '1', '9', '5', '1', '4', '1', '2', '169', '2', '1', '1', '1', '1', '1', '2', '1', '2', '1', '1', '3', '2', '2', '14', '50', '2', '1', '3', '1', '1', '2', '51', '12', '42', '1', '2', '1', '1', '1', '1', '3', '1', '1', '1', '2', '1', '1', '1', '1', '1', '4', '1', '6']}\n"
     ]
    }
   ],
   "source": [
    "def to_dol(lol):\n",
    "    \"\"\"\n",
    "    Converts a list-of-lists (LoL) to a dict-of-lists (dol)\n",
    "    using the first element in the LoL to create column names.\n",
    "    \n",
    "    :param lol: a list-of-lists where each element of the list represents a row of data\n",
    "    :returns: a dict-of-lists\n",
    "    \"\"\"\n",
    "    # Create empty dict-of-lists\n",
    "    ds = {}\n",
    "\n",
    "    # I had a version of this code that used\n",
    "    # lol.pop(0) since it made the for loop\n",
    "    # easier to read. But I changed my mind...\n",
    "    #\n",
    "    # Can you think why?\n",
    "    col_names = lol[0]\n",
    "    # Write the code to create the keys and empty lists (HINT: for loop)\n",
    "    \n",
    "    for i in col_names:\n",
    "        ds[i]= []\n",
    "    \n",
    "\n",
    "    # Then values into a list attached to each key\n",
    "    # and write the code to append values to each list\n",
    "    for row in lol[1:]:\n",
    "        for c in range(0,len(col_names)):\n",
    "            ds[col_names[c]].append(row[c])\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "ds = to_dol(clol)\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id, name, host_id, host_name, host_since, latitude, longitude, property_type, room_type, accommodates, bathrooms, bedrooms, beds, price, minimum_nights, maximum_nights, availability_365, number_of_reviews, calculated_host_listings_count\n",
      "['25339003', '40259218']\n",
      "['An Amazing 4Bedroom Home, Central London, Sleeps12', 'Large Double Room - Maida Vale']\n",
      "['Entire home/apt', 'Private room']\n"
     ]
    }
   ],
   "source": [
    "print(\", \".join(ds.keys()))\n",
    "print(ds['id'][:2])\n",
    "print(ds['name'][:2])\n",
    "print(ds['room_type'][:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer should look like:\n",
    "```\n",
    "id, name, host_id, host_name, host_since, latitude, longitude, property_type, room_type, accommodates, bathrooms, bedrooms, beds, price, minimum_nights, maximum_nights, availability_365, number_of_reviews, calculated_host_listings_count\n",
    "['25339003', '40259218']\n",
    "['An Amazing 4Bedroom Home, Central London, Sleeps12', 'Large Double Room - Maida Vale']\n",
    "['Entire home/apt', 'Private room']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.7: Convert Data Types on DoL\n",
    "\n",
    " You'll need to investigate the columns yourself in order to see what the appropraite values should be. I would suggest taking the _full_ version of the function where we check what `cdata` is so that we have one function that works for both strings and lists.\n",
    "\n",
    "Just to help get you started, here are the column names and you can create a `dtype` list to hold the _data type_ for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column (                  id) is type: int\n",
      "Column (                name) is type: str\n",
      "Column (             host_id) is type: int\n",
      "Column (           host_name) is type: str\n",
      "Column (          host_since) is type: str\n",
      "Column (            latitude) is type: float\n",
      "Column (           longitude) is type: float\n",
      "Column (       property_type) is type: str\n",
      "Column (           room_type) is type: str\n",
      "Column (        accommodates) is type: int\n",
      "Column (           bathrooms) is type: bool\n",
      "Column (            bedrooms) is type: float\n",
      "Column (                beds) is type: float\n",
      "Column (               price) is type: str\n",
      "Column (      minimum_nights) is type: int\n",
      "Column (      maximum_nights) is type: int\n",
      "Column (    availability_365) is type: int\n",
      "Column (   number_of_reviews) is type: int\n",
      "Column (calculated_host_listings_count) is type: float\n"
     ]
    }
   ],
   "source": [
    "cols  = ['id', 'name', 'host_id', 'host_name', \n",
    "        'host_since', 'latitude', 'longitude', 'property_type', \n",
    "        'room_type', 'accommodates', 'bathrooms', 'bedrooms', 'beds', \n",
    "        'price', 'minimum_nights', 'maximum_nights', \n",
    "        'availability_365', 'number_of_reviews', \n",
    "         'calculated_host_listings_count']\n",
    "#dtype=[]\n",
    "#for i in cols:\n",
    "    #dtype.append(type(ds[i][0]))\n",
    "#print(dtype)\n",
    "\n",
    "dtype = [int, str, int, str, \n",
    "         str, float, float, str, \n",
    "         str, int, bool, float, float, \n",
    "         str, int, int, int, int, float]\n",
    "\n",
    "# 'Zips up' these two lists into an iterator list of tuples!\n",
    "# Note than you cannot save the output of zip directly because\n",
    "# you can only iterate through it once.\n",
    "for d in zip(cols, dtype):\n",
    "    # Notice the more advanced formatting here:\n",
    "    # - `>20` means right-align with up to 20 characters of whitespace; notice the last line!\n",
    "    # - `d[1].__name__` gives us the name of the data type, rather than a '<class...>' output.\n",
    "    print(f\"Column ({d[0]:>20}) is type: {d[1].__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure tha tyou understand how this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the raw data to data of the appropriate\n",
    "# type: 'column data' (cdata) -> 'column type' (ctype)\n",
    "def to_type(cdata, ctype):\n",
    "    # If a string\n",
    "    if isinstance(cdata, str):\n",
    "        try:\n",
    "            if ctype==bool:\n",
    "                return cdata==True\n",
    "            else:\n",
    "                return ctype(cdata)\n",
    "        except TypeError:\n",
    "            return cdata\n",
    "    \n",
    "    # Not a string (assume list)\n",
    "    else: \n",
    "        fdata = []\n",
    "        for c in cdata:\n",
    "            try:\n",
    "                if ctype==bool:\n",
    "                    fdata.append( c=='True' )\n",
    "                else:\n",
    "                    fdata.append( ctype(c) )\n",
    "            except:\n",
    "                fdata.append( c )\n",
    "        return fdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply this! We'll copy the data to \n",
    "# new data structure only so that we know\n",
    "# we're not overwriting `ds` until we're sure\n",
    "# that the code works.\n",
    "ds2 = {}\n",
    "for d in zip(cols, dtype):\n",
    "    ds2[ d[0] ] = to_type(ds[d[0]], d[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25339003, 40259218, 20097666]\n",
      "['Emily', 'Mantas', 'Thanyawan']\n",
      "[9.0, 1.0, 1.0]\n",
      "[23, 365, 0]\n"
     ]
    }
   ],
   "source": [
    "print(ds2['id'][:3])\n",
    "print(ds2['host_name'][:3])\n",
    "print(ds2['beds'][:3])\n",
    "print(ds2['availability_365'][:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the followg:\n",
    "```\n",
    "[25339003, 40259218, 20097666]\n",
    "['Emily', 'Mantas', 'Thanyawan']\n",
    "[9.0, 1.0, 1.0]\n",
    "[23, 365, 0]\n",
    "['2020-03-01', '2020-02-08', '']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.8: Checking Basic Functionality\n",
    "\n",
    "Let's see if our new data structure broadly works by testing out some of our previous operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # We'll need this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average availability over 365 days is 129.15\n",
      "Standard deviation on minimum nights is 10.685855136581255\n",
      "Median maximum nights is 1125.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average availability over 365 days is {np.mean(ds2['availability_365'])}\")\n",
    "print(f\"Standard deviation on minimum nights is {np.std(ds2['minimum_nights'])}\")\n",
    "print(f\"Median maximum nights is {np.median(ds2['maximum_nights'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot perform reduce with flexible type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1804/3006483958.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Median price per night is {np.median(ds2['price'])}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/sds2021/lib/python3.9/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m     \"\"\"\n\u001b[0;32m-> 3655\u001b[0;31m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0m\u001b[1;32m   3656\u001b[0m                     overwrite_input=overwrite_input)\n\u001b[1;32m   3657\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/sds2021/lib/python3.9/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3562\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3564\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3565\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/sds2021/lib/python3.9/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3714\u001b[0m         \u001b[0;31m# Use mean in odd and even case to coerce data type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3715\u001b[0m         \u001b[0;31m# and check, use out array.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3716\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/sds2021/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3438\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3440\u001b[0;31m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0m\u001b[1;32m   3441\u001b[0m                           out=out, **kwargs)\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/sds2021/lib/python3.9/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot perform reduce with flexible type"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Median price per night is {np.median(ds2['price'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is this happening? Write some code below to check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$226.00', '$41.00', '$35.00', '$55.00', '$100.00']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2[\"price\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.9: Putting It All Together\n",
    "\n",
    "Here's a clue for how to solve the 'price' data problem; you will need to combine it with something we've seen earlier that allows you to iterate over a list and apply the solution to every `x` in the 'price' column. If you are nearing the end of the 2-hour practical, then may skip this task for now and work on converting the functions to a package (next task below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#float(ds2[?][0].replace('$',''))\n",
    "#float(ds2['price'][0].replace('$',''))\n",
    "ds2['price'] = to_type([ x.replace('$','') for x in ds2['price']],float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median price per night is $80.50\n"
     ]
    }
   ],
   "source": [
    "print(f\"Median price per night is ${np.median(ds2['price']):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Creating a Package from Functions\n",
    "\n",
    "Using or adapting as necessary the approach that we saw in the Live Coding session (Task 2 from Part 1) create a package called `dtools` by exporting the functions you've created above (only the final version of each, so don't export the one form Task 1.3 for instance) into a file called `__init__.py` that sits in the `dtools` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'dtools'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Practical-04-Objects.ipynb to python\n",
      "[NbConvertApp] Writing 31359 bytes to dtools/__init__.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --ClearOutputPreprocessor.enabled=True \\\n",
    "    --to python --output=dtools/__init__.py \\\n",
    "    Practical-04-Objects.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have tidied up the content of `dtools/__init__.py` you should be able to run the code below. You can actually edit the `init` file directly in Jupyter as a text file. You can compare this to the file I've created on GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    " %reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function to_dol in module __main__:\n",
      "\n",
      "to_dol(lol)\n",
      "    Converts a list-of-lists (LoL) to a dict-of-lists (dol)\n",
      "    using the first element in the LoL to create column names.\n",
      "    \n",
      "    :param lol: a list-of-lists where each element of the list represents a row of data\n",
      "    :returns: a dict-of-lists\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dtools\n",
    "help(to_dol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/crime-sample.csv not found, downloading!\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1804/3017662676.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'crime-sample.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdlol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdlol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_lol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdlol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mddol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdlol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/Documents/CASA/modules/CASA0013_fsds/i2p/dtools/__init__.py\u001b[0m in \u001b[0;36mget_url\u001b[0;34m(src, dest)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#Â Get the data using the urlopen function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mfiledata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/sds2021/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/sds2021/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/sds2021/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    633\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/sds2021/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0mhttp_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/sds2021/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/sds2021/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_302\u001b[0;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0mhttp_error_301\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_303\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_307\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_302\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/sds2021/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/sds2021/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    633\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/sds2021/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/sds2021/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/sds2021/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "url = 'https://github.com/jreades/i2p/raw/master/data/src/2019-sample-Crime.csv'\n",
    "out = os.path.join('data','crime-sample.csv')\n",
    "\n",
    "dlol = dtools.get_url(url, out)\n",
    "dlol = dtools.to_lol(dlol)\n",
    "ddol = dtools.to_dol(dlol)\n",
    "\n",
    "print(len(ddol.keys()))\n",
    "print(len(ddol['ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ddol' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1804/2610908773.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ddol' is not defined"
     ]
    }
   ],
   "source": [
    "print(ddol.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
